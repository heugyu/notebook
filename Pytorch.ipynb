{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOcNoQmXWQU7JQt+yopPypx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heugyu/notebook/blob/master/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3olIeV-4Yx5q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e09b3216-5fe8-4019-a069-554761a32151"
      },
      "source": [
        "# Pytorch 패키지 설치\n",
        "!pip3 install torch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfPKhFk9ZAhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkntvIS9aRLa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "1600e000-8cb3-4da6-a8ba-de325a8cbe9b"
      },
      "source": [
        "x = torch.tensor([[1,2,3,], [4,5,6], [7,8,9]])\n",
        "print(x.size())\n",
        "print(x.shape)\n",
        "# 차원 정보 \n",
        "print(x.ndimension())\n",
        "\n",
        "# unsqueeze(), squeeze(), view() 함수로 텐서의 랭크와 shape의 인위적 변경 가능 "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 3])\n",
            "torch.Size([3, 3])\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YBXc5SYbPSY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "582f6433-f25f-487f-9d41-b6bc85e41a39"
      },
      "source": [
        "# 정규분포에서 무작위로 값을 뽑아 텐서를 생성하는 randn()\n",
        "w = torch.randn(5, 3, dtype=torch.float)\n",
        "x = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "\n",
        "print(w.size())\n",
        "print(x.size())\n",
        "\n",
        "print(w)\n",
        "print(x)\n",
        "\n",
        "# 행렬곱은 torch.mm() 함수 사용 -> matmul\n",
        "wx = torch.mm(w,x)\n",
        "print(wx.size())\n",
        "print(wx)\n",
        "\n",
        "# (5, 3) * (3 ,2) = (5, 2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n",
            "torch.Size([3, 2])\n",
            "tensor([[-0.5459,  0.1215, -0.6685],\n",
            "        [-0.3041, -0.0787, -1.6572],\n",
            "        [-0.0633, -1.0126, -0.3969],\n",
            "        [ 0.4379, -0.3911,  0.1603],\n",
            "        [ 0.5228,  0.0526,  0.3264]])\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "torch.Size([5, 2])\n",
            "tensor([[ -3.5240,  -4.6168],\n",
            "        [ -8.8260, -10.8659],\n",
            "        [ -5.0854,  -6.5582],\n",
            "        [  0.0660,   0.2732],\n",
            "        [  2.3127,   3.2146]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFAiyX8_fWQS",
        "colab_type": "text"
      },
      "source": [
        "### Autograd\n",
        "- 데이터의 정답(ground_truth)과 모델이 예측한 결과의 차이를 산술적으로 표현한 거리(distance)\n",
        "- 학습 데이터로 계산한 거리들의 평균을 오차(loss)\n",
        "- 오차가 작은 모델일수록 정확한 모델 \n",
        "- 오차를 최소화 하는 알고리즘 중 기본 -> 경사하강법(gradient decent)\n",
        "- 경사하강법, 오차를 수학 함수로 표현 후 미분하여 함수의 기울기를 구해 loss가 최소가 되는 방향을 찾는 알고리즘\n",
        "- **Pytorch의 Autograd는 미분 계산을 자동화 하여 경사 하강법을 구현 하는 수고를 덤**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Afsf-uQcddN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9afdc6cd-13ad-45e2-8baf-6c0fa1d98d8d"
      },
      "source": [
        "# requires_grad = True\n",
        "# Pytorch의 Autograd 기능이 자동으로 계산할 때 w에 대한 미분값을 w.grad에 저장\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "a = w * 3\n",
        "l = a ** 2\n",
        "\n",
        "# l을 w로 미분하려면 연쇄법칙을 이용하여 a와 w로 차례대로 미분 \n",
        "# backward() 함수\n",
        "l.backward()\n",
        "print(w.grad)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(18.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcD45arlkoPh",
        "colab_type": "text"
      },
      "source": [
        "### 인공신경망 (ANN)\n",
        "- 인공신경망(artificial neural network)은 인간의 뇌, 혹은 신경계의 작동 방식에서 영감\n",
        "![image](https://user-images.githubusercontent.com/60495142/75842561-f968b580-5e13-11ea-98ac-c7a2eb755651.png)\n",
        "\n",
        "- 각 층에 존재하는 매개변수인 가중치(weight)에 행렬곱\n",
        "- 편향(bias)을 더해주는 것\n",
        "- 가중치는 입력 신호가 출력에 주는 영향을 계산하는 매개변수\n",
        "- 편향은 각 노드가 얼마나 데이터에 민감한지 알려주는 매개변수\n",
        "- 행렬곱의 결과는 활성화 함수(activation function)을 거쳐 결과값 산출\n",
        "- 인공 신경망의 출력층의 결과값과 정답의 오차를 계산하여 출력층의 가중치 부터 입력층의 가중치 까지 모두 경사하강법을 활용해 변경\n",
        "- 뒤에서 부터 차례대로 조정하고 최적화 하는 알고리즘 역전파(Backpropagation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXUPecFkng7b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "083bcaaf-86b3-4eed-86ca-cf82426f4dbe"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "## 데이터셋 생성 \n",
        "n_dim = 2\n",
        "# make_blobs() 함수는 예제용 데이터셋을 만들어주는 함수\n",
        "x_train, y_train = make_blobs(\n",
        "    n_samples=80,\n",
        "    n_features=n_dim,\n",
        "    centers=[[1,1], [-1,-1], [1,-1], [-1,1]],\n",
        "    shuffle=True,\n",
        "    cluster_std=0.3\n",
        ")\n",
        "\n",
        "x_test, y_test = make_blobs(\n",
        "    n_samples=20,\n",
        "    n_features=n_dim,\n",
        "    centers=[[1,1], [-1,-1], [1,-1], [-1,1]],\n",
        "    shuffle=True,\n",
        "    cluster_std=0.3\n",
        ")\n",
        "\n",
        "def label_map(y_, from_, to_):\n",
        "    y = np.copy(y_)\n",
        "    for f in from_:\n",
        "        y[y_ == f] = to_\n",
        "    return y\n",
        "\n",
        "y_train = label_map(y_train, [0,1], 0)\n",
        "y_train = label_map(y_train, [2,3], 1)\n",
        "y_test = label_map(y_test, [0,1], 0)\n",
        "y_test = label_map(y_test, [2,3], 1)\n",
        "\n",
        "## 생성된 데이터셋 시각화\n",
        "def vis_data(x, y = None, c = 'r'):\n",
        "    if y is None:\n",
        "        y = [None] * len(x)\n",
        "    for x_, y_ in zip(x, y):\n",
        "        if y_ is None:\n",
        "            plt.plot(x_[0], x_[1], '*', markerfacecolor='none', markeredgecolor=c)\n",
        "        else:\n",
        "            plt.plot(x_[0], x_[1], c + 'o' if y_ == 0 else c + '+')\n",
        "plt.figure()\n",
        "vis_data(x_train, y_train, c='r')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDwCJIOEDQCL+H5kbbkMecjcIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB29b2SOs3LG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "337d4961-3234-4218-fed8-41d5b9d9dec6"
      },
      "source": [
        "# 생성한 넘파이 벡터 형식 데이터를 파이토치 텐서로 변경\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "x_test = torch.FloatTensor(x_test)\n",
        "y_train = torch.FloatTensor(y_train)\n",
        "y_test = torch.FloatTensor(y_test)\n",
        "\n",
        "# 파이토치에서 신경망은 신경망 모듈(torch.nn.Module)을 상속 받는 파이썬 클래스로 정의\n",
        "## 신경망 모델 정의\n",
        "class NeuralNet(torch.nn.Module):\n",
        "    # super() 함수를 부르면 NeuralNet 클래스는 파이토치의 nn.Module 클래스의 속성들을 가지고 초기화\n",
        "    # input_size는 신경망에 입력되는 데이터의 차원\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        # 인공신경망을 거치는 연산을 정의\n",
        "        # torch.nn.Linear() 함수는 행렬곱과 편향을 포함하는 연산을 지원하는 객체\n",
        "        # relu, sigmoid는 활성화 함수 \n",
        "        self.liner_1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.liner_2 = torch.nn.Linear(self.hidden_size, 1)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, input_tensor):\n",
        "        # 정의한 동작들을 차례대로 실행\n",
        "        # lear_1은 입력데이터에 [input_size, hidden_size] 크기의 가중치를 행렬곱하고 편향을 더하여 [1, hidden_size] 꼴의 텐서 반환\n",
        "        # 반환된 텐서에 relu 활성화 함수 적용 -> 입력값이 0보다 작으면 0, 0보다 크면 입력값 그대로 출력\n",
        "        # linear_2로 정의된 행렬곱을 거쳐 [1, 1] 꼴로 변환 \n",
        "        # sigmoid 활성화 함수에 적용 -> 0~1 사이의 값을 반환 \n",
        "        linear1 = self.liner_1(input_tensor)\n",
        "        relu = self.relu(linear1)\n",
        "        linear2 = self.liner_2(relu)\n",
        "        output = self.sigmoid(linear2)\n",
        "        return output\n",
        "\n",
        "## 신경망 모델 생성 및 관련 변수와 알고리즘 정의\n",
        "# 신경망  객체를 생성하고 학습에 필요한 여러 변수와 알고리즘 정의\n",
        "model = NeuralNet(2,5)\n",
        "learning_rate = 0.03\n",
        "\n",
        "# ## GPU 사용\n",
        "# use_cuda = True\n",
        "# if use_cuda and torch.cuda.is_available():\n",
        "#     model.cuda()\n",
        "\n",
        "# 오차 함수 -> 이진 교차 엔트로피 (binary cross entropy)\n",
        "criterion = torch.nn.BCELoss()\n",
        "epochs = 2000\n",
        "# 새 가중치 = 가중치 - 학습률 * 가중치에 대한 기울기\n",
        "# optimizer는 step() 함수를 부를 때마다 가중치를 학습률만큼 갱신\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) \n",
        "\n",
        "## 학습 전 모델 성능 평가 \n",
        "model.eval()\n",
        "test_loss_before = criterion(model(x_test).squeeze(), y_test)\n",
        "# item() 함수는 텐서 속의 숫자를 스칼라 값으로 반환\n",
        "print(test_loss_before.item())\n",
        "\n",
        "## 신경망 학습 \n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    # 에폭마다 새로운 경사값을 계산할 것이므로 zero_grad() 함수를 호출해 경사값을 0으로 설정 \n",
        "    optimizer.zero_grad()\n",
        "    # 앞서 생성한 모델에 학습 데이터를 입력해 결과값 계산 \n",
        "    # 신경망 모델 클래스에 정의한 forward() 함수가 신경망의 결과값을 내는 함수\n",
        "    # torch.nn.module이 forward() 함수를 대신 호출\n",
        "    train_output = model(x_train)\n",
        "    train_loss = criterion(train_output.squeeze(), y_train)\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Train loss at {epoch} is {train_loss.item()}')\n",
        "    # 오차 함수를 가중치로 미분하여 오차가 최소가 되는 방향 구함\n",
        "    # 그 방향으로 모델을 학습률 만큼 이동 \n",
        "    # 역전파 코드 \n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "## 학습 후 모델 성능 평가 \n",
        "model.eval()\n",
        "test_loss = criterion(torch.squeeze(model(x_test)), y_test)\n",
        "print(test_loss.item())\n",
        "\n",
        "## 학습된 가중치 저장 \n",
        "# 학습된 모델을 state_dict() 함수 형태로 바꾸어 .pt로 저장 \n",
        "# state_dict() 함수는 모델 내 가중치들이 딕셔너리 형태로 \n",
        "#{연산이름:가중치 텐서와 편향텐서}\n",
        "# torch.save(model.state_dict(), './model.pt')\n",
        "\n",
        "## 저장된 가중치 불러와 새로운 모델에 적용(전이 학습)\n",
        "# new_model = NeuralNet(2, 5)\n",
        "# new_model.load_state_dict(torch.load('./model.pt'))\n",
        "# new_model.eval()\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7031499147415161\n",
            "Train loss at 0 is 0.6978460550308228\n",
            "Train loss at 100 is 0.5836606025695801\n",
            "Train loss at 200 is 0.45631012320518494\n",
            "Train loss at 300 is 0.3186921775341034\n",
            "Train loss at 400 is 0.21442434191703796\n",
            "Train loss at 500 is 0.14858084917068481\n",
            "Train loss at 600 is 0.1082814559340477\n",
            "Train loss at 700 is 0.08318857848644257\n",
            "Train loss at 800 is 0.06657259166240692\n",
            "Train loss at 900 is 0.05499807745218277\n",
            "Train loss at 1000 is 0.04658583551645279\n",
            "Train loss at 1100 is 0.04029931128025055\n",
            "Train loss at 1200 is 0.03542359545826912\n",
            "Train loss at 1300 is 0.03153332322835922\n",
            "Train loss at 1400 is 0.02836519107222557\n",
            "Train loss at 1500 is 0.025739187374711037\n",
            "Train loss at 1600 is 0.023530926555395126\n",
            "Train loss at 1700 is 0.02165025658905506\n",
            "Train loss at 1800 is 0.020029939711093903\n",
            "Train loss at 1900 is 0.018620384857058525\n",
            "0.036126069724559784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPxhcL2X2pUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}